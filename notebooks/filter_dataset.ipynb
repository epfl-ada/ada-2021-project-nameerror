{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "filter_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMFyLGeEEGou"
      },
      "source": [
        "!mkdir data\n",
        "!mkdir data/in\n",
        "!mkdir data/out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "id": "iIRL75Z4ZXFy",
        "outputId": "283f3bc9-eaa2-44ca-e723-5af1118449f8"
      },
      "source": [
        "!pip install pandas==1.0.5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandas==1.0.5\n",
            "  Downloading pandas-1.0.5-cp37-cp37m-manylinux1_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 27.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.0.5) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==1.0.5) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.0.5) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.6.1->pandas==1.0.5) (1.15.0)\n",
            "Installing collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.0.5 which is incompatible.\u001b[0m\n",
            "Successfully installed pandas-1.0.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: pandas\n",
            "Version: 1.0.5\n",
            "Summary: Powerful data structures for data analysis, time series, and statistics\n",
            "Home-page: https://pandas.pydata.org\n",
            "Author: None\n",
            "Author-email: None\n",
            "License: BSD\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: python-dateutil, numpy, pytz\n",
            "Required-by: xarray, vega-datasets, statsmodels, sklearn-pandas, seaborn, pymc3, plotnine, pandas-profiling, pandas-gbq, pandas-datareader, mlxtend, mizani, holoviews, gspread-dataframe, google-colab, fix-yahoo-finance, fbprophet, fastai, cufflinks, cmdstanpy, arviz, altair\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCGHbQCHjkyQ"
      },
      "source": [
        "!pip show pandas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdo_fw5btEhl",
        "outputId": "ff61fbc2-75dc-43f5-9c72-73f7044f49ee"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Laefej44PW8d"
      },
      "source": [
        "DATA_IN = 'data/in'\n",
        "DATA_OUT = '/content/drive/MyDrive/quotebank_filtered'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYsamBTh17zL",
        "outputId": "b2cc5cd1-8c92-456d-c236-cfac127b85c9"
      },
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "def prepare_tokens(tokens, stemmer):\n",
        "  return map(\n",
        "      # to avoid any multithreading issues, stemmer is always passed from outside\n",
        "      stemmer.stem, \n",
        "      map(lambda word: word.lower(), tokens)\n",
        "  )\n",
        "\n",
        "def is_topic_related(text, term_set_to_look_for, stemmer):\n",
        "  tokens = prepare_tokens(word_tokenize(text), stemmer)\n",
        "  return bool(set(tokens) & term_set_to_look_for)\n",
        "\n",
        "class ChunkProcessingFilter:\n",
        "  def __init__(self, *terms_to_look_for):\n",
        "    self.set_to_look_for = set(\n",
        "        prepare_tokens(terms_to_look_for, PorterStemmer()))\n",
        "\n",
        "  def __call__(self, chunk):\n",
        "    stemmer = PorterStemmer()\n",
        "    mask = chunk.apply(\n",
        "        lambda row: is_topic_related(\n",
        "            row.quotation, self.set_to_look_for, stemmer),\n",
        "        axis=1)\n",
        "    return chunk[mask]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj5ookJGGT7J"
      },
      "source": [
        "import pandas as pd\n",
        "import itertools\n",
        "from functools import reduce\n",
        "from multiprocessing import Pool\n",
        "\n",
        "def filter_stream_by_terms(in_file, terms, chunksize, poolworkers=2):\n",
        "  processing_filter = ChunkProcessingFilter(*terms)\n",
        "  df_reader = pd.read_json(in_file, lines=True, compression='bz2', chunksize=200000)\n",
        "  try:\n",
        "    with Pool(poolworkers) as pool:\n",
        "      return reduce(\n",
        "        lambda acc, new_el: pd.concat([acc, new_el]),\n",
        "        pool.imap_unordered(processing_filter, df_reader)\n",
        "      )\n",
        "  finally:\n",
        "    df_reader.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPFrw6JyUnTR"
      },
      "source": [
        "quotebank_files_of_years = {\n",
        "    # 2020: 'https://zenodo.org/record/4277311/files/quotes-2020.json.bz2?download=1',\n",
        "    2019: 'https://zenodo.org/record/4277311/files/quotes-2019.json.bz2?download=1',\n",
        "    2018: 'https://zenodo.org/record/4277311/files/quotes-2018.json.bz2?download=1',\n",
        "    2017: 'https://zenodo.org/record/4277311/files/quotes-2017.json.bz2?download=1',\n",
        "    2016: 'https://zenodo.org/record/4277311/files/quotes-2016.json.bz2?download=1',\n",
        "    2015: 'https://zenodo.org/record/4277311/files/quotes-2015.json.bz2?download=1'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXKH6bBWVLA7",
        "outputId": "2d965fbb-768d-4210-fb63-061e9f226f35"
      },
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "def download_file(url, out_file):\n",
        "  \"\"\" Downloads file from the given url \"\"\"\n",
        "  os.system(f'wget {url} -O {out_file}')\n",
        "\n",
        "TERMS = ['vegan', 'vegetarian', 'veget', 'plant-based']\n",
        "CHUNKSIZE = 200000\n",
        "\n",
        "for year, file_url in quotebank_files_of_years.items():\n",
        "  # Specify download path\n",
        "  file_path = f'{DATA_IN}/quotebank_{year}.json.bz2'\n",
        "  print(f'Processing Quotebank for year {year}')\n",
        "  # Download file\n",
        "  print(f'\\tDownloading file: {file_url}')\n",
        "  download_file(file_url, file_path)\n",
        "  print(f'\\tThe file downloaded to {file_path}')\n",
        "  # Filter the quotebank of the given year\n",
        "  print('\\tProcessing the file...')\n",
        "  filtered_data = filter_stream_by_terms(file_path, TERMS, CHUNKSIZE)\n",
        "  # Save the filtered dataframe to a new file\n",
        "  out_file = f'{DATA_OUT}/quotebank_filtered_{year}.json.bz2'\n",
        "  print(f'\\tSaving the result to {out_file}')\n",
        "  filtered_data.to_json(out_file, \n",
        "                        compression='bz2', \n",
        "                        orient='records', \n",
        "                        lines=True)\n",
        "  # Download the filtered file from Google Colab\n",
        "  # files.download(out_file) \n",
        "  # Remove the original file of the quotebank for the given year\n",
        "  print(f'\\tDeleting {file_path}...')\n",
        "  os.remove(file_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Quotebank for year 2019\n",
            "\tDownloading file: https://zenodo.org/record/4277311/files/quotes-2019.json.bz2?download=1\n",
            "\tThe file downloaded to data/in/quotebank_2019.json.bz2\n",
            "\tProcessing the file...\n",
            "\tSaving the result to /content/drive/MyDrive/quotebank_filtered/quotebank_filtered_2019.json.bz2\n",
            "\tDeleting data/in/quotebank_2019.json.bz2...\n",
            "Processing Quotebank for year 2018\n",
            "\tDownloading file: https://zenodo.org/record/4277311/files/quotes-2018.json.bz2?download=1\n",
            "\tThe file downloaded to data/in/quotebank_2018.json.bz2\n",
            "\tProcessing the file...\n"
          ]
        }
      ]
    }
  ]
}